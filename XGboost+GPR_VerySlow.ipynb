{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22989d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern, WhiteKernel\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...\")\n",
    "df = pd.read_csv('experiment_design_27points.csv')\n",
    "\n",
    "# ‡πÅ‡∏¢‡∏Å Input ‡πÅ‡∏•‡∏∞ Output\n",
    "X = df[['Proportion1', 'Proportion2', 'Temp_C', 'Pressure_bar']]\n",
    "y = df.filter(like='Alpha_')  # Alpha_1Hz ‡∏ñ‡∏∂‡∏á Alpha_1000Hz\n",
    "\n",
    "print(f\"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Data Points: {len(df)}\")\n",
    "print(f\"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Input Features: {X.shape[1]}\")\n",
    "print(f\"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Output Features (Hz): {y.shape[1]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Standardize Input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPR (‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ GPR ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô)\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ============================================================\n",
    "# 3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤+‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥)\n",
    "# ============================================================\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏∏‡∏Å‡πÜ 10 Hz (1, 10, 20, ..., 100 Hz) ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "selected_hz = [f'Alpha_{i}Hz' for i in range(1, 101, 1)]  # 1-100 Hz\n",
    "selected_hz = [col for col in selected_hz if col in y.columns]\n",
    "y_selected = y[selected_hz]\n",
    "\n",
    "print(f\"‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà: {len(selected_hz)} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost (‡πÉ‡∏ä‡πâ Cross-Validation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô XGBoost Models...\")\n",
    "\n",
    "xgb_models = {}\n",
    "xgb_scores = []\n",
    "\n",
    "for col in y_selected.columns:\n",
    "    # ‡πÉ‡∏ä‡πâ regularization parameters ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î overfitting\n",
    "    model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_estimators=50,       # ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô trees ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î overfitting\n",
    "        max_depth=3,           # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏ï‡πà‡∏≥ = complexity ‡∏ï‡πà‡∏≥\n",
    "        learning_rate=0.1,\n",
    "        reg_alpha=0.1,         # L1 regularization\n",
    "        reg_lambda=1.0,        # L2 regularization\n",
    "        min_child_weight=3,    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÉ‡∏ô leaf\n",
    "        subsample=0.8,         # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ tree\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method='hist',  # ‡πÉ‡∏ä‡πâ GPU\n",
    "        device='cuda'            # ‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ CUDA\n",
    "    )\n",
    "    \n",
    "    # Leave-One-Out Cross-Validation (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢)\n",
    "    loo = LeaveOneOut()\n",
    "    cv_scores = cross_val_score(model, X, y_selected[col], cv=5, scoring='r2')\n",
    "    \n",
    "    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "    model.fit(X, y_selected[col])\n",
    "    xgb_models[col] = model\n",
    "    xgb_scores.append(np.mean(cv_scores))\n",
    "\n",
    "print(f\"‚úÖ XGBoost Average R¬≤ (CV): {np.mean(xgb_scores):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Gaussian Process Regression \n",
    "#    (‡πÉ‡∏´‡πâ Uncertainty estimate + interpolation ‡∏î‡∏µ)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Gaussian Process Regression Models...\")\n",
    "\n",
    "gpr_models = {}\n",
    "gpr_scores = []\n",
    "\n",
    "# Kernel: RBF + White noise (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢)\n",
    "kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "\n",
    "for i, col in enumerate(y_selected.columns):\n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        n_restarts_optimizer=5,  # ‡∏´‡∏≤ hyperparameter ‡∏ó‡∏µ‡πà‡∏î‡∏µ\n",
    "        alpha=0.1,               # noise level ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏° robust\n",
    "        normalize_y=True,        # normalize output\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # ‡πÉ‡∏ä‡πâ scaled input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPR\n",
    "    gpr.fit(X_scaled, y_selected[col])\n",
    "    gpr_models[col] = gpr\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì score\n",
    "    y_pred = gpr.predict(X_scaled)\n",
    "    score = r2_score(y_selected[col], y_pred)\n",
    "    gpr_scores.append(score)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß {i + 1}/{len(y_selected.columns)} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\")\n",
    "\n",
    "print(f\"‚úÖ GPR Average R¬≤ (Training): {np.mean(gpr_scores):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Ensemble Prediction (‡∏£‡∏ß‡∏° XGBoost + GPR)\n",
    "# ============================================================\n",
    "def ensemble_predict(x_input, return_std=False):\n",
    "    \"\"\"\n",
    "    ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° XGBoost ‡πÅ‡∏•‡∏∞ GPR\n",
    "    - XGBoost: ‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö non-linear relationships\n",
    "    - GPR: ‡πÉ‡∏´‡πâ uncertainty estimate + smooth interpolation\n",
    "    \"\"\"\n",
    "    x_array = np.array(x_input).reshape(1, -1)\n",
    "    x_scaled = scaler.transform(x_array)\n",
    "    \n",
    "    predictions = []\n",
    "    uncertainties = []\n",
    "    \n",
    "    for col in y_selected.columns:\n",
    "        # XGBoost prediction\n",
    "        xgb_pred = xgb_models[col].predict(x_array)[0]\n",
    "        \n",
    "        # GPR prediction with uncertainty\n",
    "        gpr_pred, gpr_std = gpr_models[col].predict(x_scaled, return_std=True)\n",
    "        gpr_pred = gpr_pred[0]\n",
    "        gpr_std = gpr_std[0]\n",
    "        \n",
    "        # Weighted average: ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å GPR ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤ uncertainty ‡∏ï‡πà‡∏≥\n",
    "        weight_gpr = 1 / (1 + gpr_std)  # uncertainty ‡∏ï‡πà‡∏≥ = weight ‡∏™‡∏π‡∏á\n",
    "        weight_xgb = 1 - weight_gpr * 0.5\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = weight_xgb + weight_gpr\n",
    "        ensemble_pred = (weight_xgb * xgb_pred + weight_gpr * gpr_pred) / total_weight\n",
    "        \n",
    "        predictions.append(ensemble_pred)\n",
    "        uncertainties.append(gpr_std)\n",
    "    \n",
    "    if return_std:\n",
    "        return np.array(predictions), np.array(uncertainties)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# ============================================================\n",
    "# 7. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Target Output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Target Output...\")\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ Alpha ‡∏™‡∏π‡∏á (0.7-0.98) ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 1-100 Hz\n",
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "target_output = np.linspace(0.7, 0.98, len(selected_hz))\n",
    "\n",
    "# ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á:\n",
    "# target_output = np.array([0.8] * len(selected_hz))  # ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà 0.8\n",
    "\n",
    "print(f\"  Target range: {target_output.min():.2f} - {target_output.max():.2f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. Objective Function (‡∏£‡∏ß‡∏° MSE + Uncertainty penalty)\n",
    "# ============================================================\n",
    "def objective_with_uncertainty(x):\n",
    "    \"\"\"\n",
    "    Objective function ‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ó‡∏±‡πâ‡∏á MSE ‡πÅ‡∏•‡∏∞ Uncertainty\n",
    "    - ‡∏•‡∏î MSE: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á target\n",
    "    - ‡∏•‡∏î Uncertainty: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à\n",
    "    \"\"\"\n",
    "    predictions, uncertainties = ensemble_predict(x, return_std=True)\n",
    "    \n",
    "    # Mean Squared Error\n",
    "    mse = np.mean((predictions - target_output) ** 2)\n",
    "    \n",
    "    # Uncertainty penalty (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£ extrapolate)\n",
    "    uncertainty_penalty = np.mean(uncertainties) * 0.1\n",
    "    \n",
    "    return mse + uncertainty_penalty\n",
    "\n",
    "def objective_mse_only(x):\n",
    "    \"\"\"Objective ‡πÅ‡∏ö‡∏ö MSE ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\"\"\"\n",
    "    predictions = ensemble_predict(x, return_std=False)\n",
    "    mse = np.mean((predictions - target_output) ** 2)\n",
    "    return mse\n",
    "\n",
    "# ============================================================\n",
    "# 9. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Bounds ‡πÅ‡∏•‡∏∞ Constraints\n",
    "# ============================================================\n",
    "bounds = [\n",
    "    (X['Proportion1'].min(), X['Proportion1'].max()),\n",
    "    (X['Proportion2'].min(), X['Proportion2'].max()),\n",
    "    (X['Temp_C'].min(), X['Temp_C'].max()),\n",
    "    (X['Pressure_bar'].min(), X['Pressure_bar'].max()),\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä ‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á Input:\")\n",
    "print(f\"  Proportion1:  [{bounds[0][0]:.1f}, {bounds[0][1]:.1f}]\")\n",
    "print(f\"  Proportion2:  [{bounds[1][0]:.1f}, {bounds[1][1]:.1f}]\")\n",
    "print(f\"  Temp_C:       [{bounds[2][0]:.1f}, {bounds[2][1]:.1f}]\")\n",
    "print(f\"  Pressure_bar: [{bounds[3][0]:.2f}, {bounds[3][1]:.2f}]\")\n",
    "\n",
    "# ============================================================\n",
    "# 10. Global Optimization ‡∏î‡πâ‡∏ß‡∏¢ Differential Evolution\n",
    "#     (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á Local Minima)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Optimal ‡∏î‡πâ‡∏ß‡∏¢ Differential Evolution...\")\n",
    "\n",
    "result_de = differential_evolution(\n",
    "    objective_with_uncertainty,\n",
    "    bounds,\n",
    "    seed=42,\n",
    "    maxiter=200,\n",
    "    popsize=15,\n",
    "    mutation=(0.5, 1),\n",
    "    recombination=0.7,\n",
    "    polish=True,  # polish with L-BFGS-B\n",
    "    disp=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DE Optimization ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\")\n",
    "\n",
    "# ============================================================\n",
    "# 11. Local Refinement ‡∏î‡πâ‡∏ß‡∏¢ L-BFGS-B\n",
    "# ============================================================\n",
    "print(\"\\nüîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á Refine ‡∏î‡πâ‡∏ß‡∏¢ L-BFGS-B...\")\n",
    "\n",
    "result_final = minimize(\n",
    "    objective_mse_only,\n",
    "    result_de.x,\n",
    "    method='L-BFGS-B',\n",
    "    bounds=bounds,\n",
    "    options={'maxiter': 500}\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 12. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÜ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Proportion1:   {result_final.x[0]:.4f}\")\n",
    "print(f\"  Proportion2:   {result_final.x[1]:.4f}\")\n",
    "print(f\"  Temp_C:        {result_final.x[2]:.4f}\")\n",
    "print(f\"  Pressure_bar:  {result_final.x[3]:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á Predicted Output\n",
    "final_pred, final_std = ensemble_predict(result_final.x, return_std=True)\n",
    "final_mse = np.mean((final_pred - target_output) ** 2)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(f\"\\nüìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:\")\n",
    "print(f\"  MSE:  {final_mse:.6f}\")\n",
    "print(f\"  RMSE: {final_rmse:.6f}\")\n",
    "print(f\"  Mean Uncertainty: {np.mean(final_std):.4f}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "print(f\"\\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏ó‡∏∏‡∏Å‡πÜ 10 Hz):\")\n",
    "print(f\"{'Hz':>6} | {'Target':>8} | {'Predicted':>10} | {'Error':>8} | {'Uncertainty':>12}\")\n",
    "print(\"-\" * 55)\n",
    "for i in range(0, len(selected_hz), 10):\n",
    "    hz_label = selected_hz[i].replace('Alpha_', '').replace('Hz', '')\n",
    "    print(f\"{hz_label:>6} | {target_output[i]:>8.4f} | {final_pred[i]:>10.4f} | {abs(final_pred[i]-target_output[i]):>8.4f} | {final_std[i]:>12.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 13. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á Interpolation ‡∏´‡∏£‡∏∑‡∏≠ Extrapolation\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚ö†Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Interpolation Check):\")\n",
    "\n",
    "optimal_x = result_final.x\n",
    "in_range = True\n",
    "for i, col in enumerate(['Proportion1', 'Proportion2', 'Temp_C', 'Pressure_bar']):\n",
    "    min_val = X[col].min()\n",
    "    max_val = X[col].max()\n",
    "    val = optimal_x[i]\n",
    "    \n",
    "    if val < min_val or val > max_val:\n",
    "        print(f\"  ‚ö†Ô∏è {col}: {val:.4f} ‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á [{min_val:.2f}, {max_val:.2f}]\")\n",
    "        in_range = False\n",
    "    else:\n",
    "        percent = (val - min_val) / (max_val - min_val) * 100\n",
    "        print(f\"  ‚úÖ {col}: {val:.4f} (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà {percent:.1f}% ‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á)\")\n",
    "\n",
    "if in_range:\n",
    "    print(\"\\n‚úÖ ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á Interpolation - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è ‡∏ö‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á - ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô\")\n",
    "\n",
    "# ============================================================\n",
    "# 14. ‡∏´‡∏≤ Top 5 Candidates (‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Multi-start Optimization)...\")\n",
    "\n",
    "candidates = []\n",
    "for i in range(10):\n",
    "    # Random starting point\n",
    "    x0_random = [\n",
    "        np.random.uniform(bounds[0][0], bounds[0][1]),\n",
    "        np.random.uniform(bounds[1][0], bounds[1][1]),\n",
    "        np.random.uniform(bounds[2][0], bounds[2][1]),\n",
    "        np.random.uniform(bounds[3][0], bounds[3][1]),\n",
    "    ]\n",
    "    \n",
    "    result_temp = minimize(\n",
    "        objective_mse_only,\n",
    "        x0_random,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': 200}\n",
    "    )\n",
    "    \n",
    "    candidates.append({\n",
    "        'x': result_temp.x,\n",
    "        'mse': result_temp.fun\n",
    "    })\n",
    "\n",
    "# Sort by MSE\n",
    "candidates = sorted(candidates, key=lambda c: c['mse'])\n",
    "\n",
    "print(\"\\nüèÖ Top 5 ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ:\")\n",
    "print(f\"{'Rank':>4} | {'Proportion1':>11} | {'Proportion2':>11} | {'Temp_C':>8} | {'Pressure':>10} | {'MSE':>10}\")\n",
    "print(\"-\" * 75)\n",
    "for i, c in enumerate(candidates[:5]):\n",
    "    print(f\"{i+1:>4} | {c['x'][0]:>11.4f} | {c['x'][1]:>11.4f} | {c['x'][2]:>8.4f} | {c['x'][3]:>10.4f} | {c['mse']:>10.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c84984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå\n",
    "df = pd.read_csv('material_100hz_data.csv')\n",
    "\n",
    "# ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡πÉ‡∏ä‡πâ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå)\n",
    "X = df.iloc[:, :-1]  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå \"‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô\" ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (Features)\n",
    "y = df.iloc[:, -1]   # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ \"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\" (Target/Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1226d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:  0.8997317151054836\n",
      "MSE:  3.208815475941383e-05\n",
      "RMSE:  3.208815475941383e-05\n"
     ]
    }
   ],
   "source": [
    "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô 80% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ó‡∏£‡∏ô ‡πÅ‡∏•‡∏∞ 20% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á XGBoost Regressor\n",
    "xgb_model = XGBRegressor(random_state=1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "print(\"R2 Score: \", r2_score(y_test, y_pred))\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE: \", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b24273",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m y.columns:\n\u001b[32m     15\u001b[39m     model = XGBRegressor(random_state=\u001b[32m1\u001b[39m, n_estimators=\u001b[32m100\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     models[col] = model\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 0.5 ‡πÑ‡∏õ 0.3)\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1370\u001b[39m, in \u001b[36mXGBModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1367\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1368\u001b[39m     obj = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28mself\u001b[39m._set_evaluation_result(evals_result)\n\u001b[32m   1385\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\training.py:199\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    201\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\core.py:2434\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2430\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2432\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2433\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2434\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2437\u001b[39m     )\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2439\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "df = pd.read_csv('material_100hz_data.csv')\n",
    "X = df.iloc[:, :4]   # Proportion1, Proportion2, Temp_C, Pressure_bar\n",
    "y = df.iloc[:, 4:]   # Alpha_1Hz ‡∏ñ‡∏∂‡∏á Alpha_100Hz\n",
    "\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô XGBoost model ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Hz\n",
    "models = {}\n",
    "for col in y.columns:\n",
    "    model = XGBRegressor(random_state=1, n_estimators=100)\n",
    "    model.fit(X, y[col])\n",
    "    models[col] = model\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 0.5 ‡πÑ‡∏õ 0.3)\n",
    "# ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "target_output = np.linspace(0.1, 0.98, 100)  # 0.5 ‡∏ó‡∏µ‡πà 1Hz ‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢‡πÜ ‡∏ñ‡∏∂‡∏á 0.3 ‡∏ó‡∏µ‡πà 100Hz\n",
    "\n",
    "# ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á:\n",
    "# target_output = [0.5, 0.5, 0.5, 0.4, 0.4, 0.4, 0.4, 0.4, 0.3, ...] # ‡πÉ‡∏™‡πà‡∏Ñ‡∏£‡∏ö 100 ‡∏Ñ‡πà‡∏≤\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô objective: ‡∏´‡∏≤ input ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ output ‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á target ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "def objective(x):\n",
    "    predictions = []\n",
    "    for i, col in enumerate(y.columns):\n",
    "        pred = models[col].predict([x])[0]\n",
    "        predictions.append(pred)\n",
    "    predictions = np.array(predictions)\n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Mean Squared Error\n",
    "    mse = np.mean((predictions - target_output) ** 2)\n",
    "    return mse\n",
    "\n",
    "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á input (min, max ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)\n",
    "bounds = [\n",
    "    (X['Proportion1'].min(), X['Proportion1'].max()),   # Proportion1\n",
    "    (X['Proportion2'].min(), X['Proportion2'].max()),   # Proportion2  \n",
    "    (X['Temp_C'].min(), X['Temp_C'].max()),             # Temp_C\n",
    "    (X['Pressure_bar'].min(), X['Pressure_bar'].max()), # Pressure_bar\n",
    "]\n",
    "\n",
    "# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢\n",
    "x0 = X.mean().values\n",
    "\n",
    "# ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ optimal\n",
    "result = minimize(objective, x0, method='L-BFGS-B', bounds=bounds)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "print(\"=\" * 50)\n",
    "print(\"‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:\")\n",
    "print(f\"  Proportion1:   {result.x[0]:.4f}\")\n",
    "print(f\"  Proportion2:   {result.x[1]:.4f}\")\n",
    "print(f\"  Temp_C:        {result.x[2]:.4f}\")\n",
    "print(f\"  Pressure_bar:  {result.x[3]:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"MSE (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡∏≤‡∏î‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô): {result.fun:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce235f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...\n",
      "‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Data Points: 27\n",
      "‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Input Features: 4\n",
      "‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Output Features (Hz): 1000\n",
      "‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà: 100 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
      "\n",
      "============================================================\n",
      "ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô XGBoost Models...\n",
      "‚úÖ XGBoost Average R¬≤ (CV): -1.1768\n",
      "\n",
      "============================================================\n",
      "üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Gaussian Process Regression Models...\n",
      "  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß 20/100 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
      "  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß 40/100 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
      "  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß 60/100 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
      "  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß 80/100 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
      "  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß 100/100 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
      "‚úÖ GPR Average R¬≤ (Training): 0.9282\n",
      "\n",
      "============================================================\n",
      "üéØ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Target Output...\n",
      "  Target range: 0.70 - 0.98\n",
      "\n",
      "üìä ‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á Input:\n",
      "  Proportion1:  [11.0, 88.0]\n",
      "  Proportion2:  [12.0, 89.0]\n",
      "  Temp_C:       [120.3, 129.8]\n",
      "  Pressure_bar: [4.02, 4.98]\n",
      "\n",
      "============================================================\n",
      "üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Optimal ‡∏î‡πâ‡∏ß‡∏¢ Differential Evolution...\n",
      "‚úÖ DE Optimization ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\n",
      "\n",
      "üîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á Refine ‡∏î‡πâ‡∏ß‡∏¢ L-BFGS-B...\n",
      "\n",
      "============================================================\n",
      "üèÜ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:\n",
      "============================================================\n",
      "  Proportion1:   34.2802\n",
      "  Proportion2:   63.5963\n",
      "  Temp_C:        125.2444\n",
      "  Pressure_bar:  4.6914\n",
      "============================================================\n",
      "\n",
      "üìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:\n",
      "  MSE:  0.085399\n",
      "  RMSE: 0.292232\n",
      "  Mean Uncertainty: 0.2389\n",
      "\n",
      "üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏ó‡∏∏‡∏Å‡πÜ 10 Hz):\n",
      "    Hz |   Target |  Predicted |    Error |  Uncertainty\n",
      "-------------------------------------------------------\n",
      "     1 |   0.7000 |     0.6073 |   0.0927 |       0.2397\n",
      "    11 |   0.7283 |     0.5962 |   0.1321 |       0.2395\n",
      "    21 |   0.7566 |     0.5725 |   0.1841 |       0.2234\n",
      "    31 |   0.7848 |     0.6297 |   0.1552 |       0.2436\n",
      "    41 |   0.8131 |     0.6231 |   0.1901 |       0.2732\n",
      "    51 |   0.8414 |     0.5307 |   0.3108 |       0.2281\n",
      "    61 |   0.8697 |     0.6820 |   0.1877 |       0.2496\n",
      "    71 |   0.8980 |     0.5696 |   0.3284 |       0.2503\n",
      "    81 |   0.9263 |     0.5796 |   0.3467 |       0.2378\n",
      "    91 |   0.9545 |     0.5975 |   0.3570 |       0.2070\n",
      "\n",
      "============================================================\n",
      "‚ö†Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Interpolation Check):\n",
      "  ‚úÖ Proportion1: 34.2802 (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 30.2% ‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á)\n",
      "  ‚úÖ Proportion2: 63.5963 (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 67.0% ‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á)\n",
      "  ‚úÖ Temp_C: 125.2444 (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 52.0% ‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á)\n",
      "  ‚úÖ Pressure_bar: 4.6914 (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà 69.9% ‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á)\n",
      "\n",
      "‚úÖ ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á Interpolation - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠!\n",
      "\n",
      "============================================================\n",
      "üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Multi-start Optimization)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 315\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m):\n\u001b[32m    307\u001b[39m     \u001b[38;5;66;03m# Random starting point\u001b[39;00m\n\u001b[32m    308\u001b[39m     x0_random = [\n\u001b[32m    309\u001b[39m         np.random.uniform(bounds[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m], bounds[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m]),\n\u001b[32m    310\u001b[39m         np.random.uniform(bounds[\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m], bounds[\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m]),\n\u001b[32m    311\u001b[39m         np.random.uniform(bounds[\u001b[32m2\u001b[39m][\u001b[32m0\u001b[39m], bounds[\u001b[32m2\u001b[39m][\u001b[32m1\u001b[39m]),\n\u001b[32m    312\u001b[39m         np.random.uniform(bounds[\u001b[32m3\u001b[39m][\u001b[32m0\u001b[39m], bounds[\u001b[32m3\u001b[39m][\u001b[32m1\u001b[39m]),\n\u001b[32m    313\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     result_temp = \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobjective_mse_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx0_random\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     candidates.append({\n\u001b[32m    324\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mx\u001b[39m\u001b[33m'\u001b[39m: result_temp.x,\n\u001b[32m    325\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mmse\u001b[39m\u001b[33m'\u001b[39m: result_temp.fun\n\u001b[32m    326\u001b[39m     })\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# Sort by MSE\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:413\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m    412\u001b[39m \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:375\u001b[39m, in \u001b[36mScalarFunction._update_grad\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._orig_grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_fun()\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m \u001b[38;5;28mself\u001b[39m.g = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m.g_updated = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:41\u001b[39m, in \u001b[36m_ScalarGradWrapper.__call__\u001b[39m\u001b[34m(self, x, f0, **kwds)\u001b[39m\n\u001b[32m     39\u001b[39m     g = np.atleast_1d(\u001b[38;5;28mself\u001b[39m.grad(np.copy(x), *\u001b[38;5;28mself\u001b[39m.args))\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.grad \u001b[38;5;129;01min\u001b[39;00m FD_METHODS:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     g, dct = \u001b[43mapprox_derivative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinite_diff_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += dct[\u001b[33m'\u001b[39m\u001b[33mnfev\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     49\u001b[39m \u001b[38;5;28mself\u001b[39m.ngev += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:593\u001b[39m, in \u001b[36mapprox_derivative\u001b[39m\u001b[34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs, full_output, workers)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m MapWrapper(workers) \u001b[38;5;28;01mas\u001b[39;00m mf:\n\u001b[32m    592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sparsity \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m         J, _nfev = \u001b[43m_dense_difference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43muse_one_sided\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    596\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    597\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(sparsity) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sparsity) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:686\u001b[39m, in \u001b[36m_dense_difference\u001b[39m\u001b[34m(fun, x0, f0, h, use_one_sided, method, workers)\u001b[39m\n\u001b[32m    684\u001b[39m f_evals = workers(fun, x_generator2(x0, h))\n\u001b[32m    685\u001b[39m dx = [(x0[i] + h[i]) - x0[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)]\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m df = \u001b[43m[\u001b[49m\u001b[43mf_eval\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mf0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf_eval\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf_evals\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    687\u001b[39m df_dx = [delf / delx \u001b[38;5;28;01mfor\u001b[39;00m delf, delx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df, dx)]\n\u001b[32m    688\u001b[39m nfev += \u001b[38;5;28mlen\u001b[39m(df_dx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\optimize\\_numdiff.py:879\u001b[39m, in \u001b[36m_Fun_Wrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m xp.isdtype(x.dtype, \u001b[33m\"\u001b[39m\u001b[33mreal floating\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    877\u001b[39m     x = xp.astype(x, \u001b[38;5;28mself\u001b[39m.x0.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m f = np.atleast_1d(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`fun` return value has \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    882\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mmore than 1 dimension.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\scipy\\_lib\\_util.py:603\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    601\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    602\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m603\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    604\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 190\u001b[39m, in \u001b[36mobjective_mse_only\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjective_mse_only\u001b[39m(x):\n\u001b[32m    189\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Objective ‡πÅ‡∏ö‡∏ö MSE ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     predictions = \u001b[43mensemble_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_std\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     mse = np.mean((predictions - target_output) ** \u001b[32m2\u001b[39m)\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mse\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mensemble_predict\u001b[39m\u001b[34m(x_input, return_std)\u001b[39m\n\u001b[32m    128\u001b[39m uncertainties = []\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m y_selected.columns:\n\u001b[32m    131\u001b[39m     \u001b[38;5;66;03m# XGBoost prediction\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     xgb_pred = \u001b[43mxgb_models\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_array\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    134\u001b[39m     \u001b[38;5;66;03m# GPR prediction with uncertainty\u001b[39;00m\n\u001b[32m    135\u001b[39m     gpr_pred, gpr_std = gpr_models[col].predict(x_scaled, return_std=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py:1444\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1403\u001b[39m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[32m   1404\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m   1405\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1411\u001b[39m     iteration_range: Optional[IterationRange] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1412\u001b[39m ) -> ArrayLike:\n\u001b[32m   1413\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Predict with `X`.  If the model is trained with early stopping, then\u001b[39;00m\n\u001b[32m   1414\u001b[39m \u001b[33;03m    :py:attr:`best_iteration` is used automatically. The estimator uses\u001b[39;00m\n\u001b[32m   1415\u001b[39m \u001b[33;03m    `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1442\u001b[39m \n\u001b[32m   1443\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iteration_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_can_use_inplace_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[39m, in \u001b[36m_GeneratorContextManager.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args, \u001b[38;5;28mself\u001b[39m.kwds, \u001b[38;5;28mself\u001b[39m.func\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mgenerator didn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt yield\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\config.py:181\u001b[39m, in \u001b[36mconfig_context\u001b[39m\u001b[34m(**new_config)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;129m@config_doc\u001b[39m(\n\u001b[32m    157\u001b[39m     header=\u001b[33m\"\"\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m )\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconfig_context\u001b[39m(**new_config: Any) -> Iterator[\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m    180\u001b[39m     old_config = get_config().copy()\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     \u001b[43mset_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\config.py:108\u001b[39m, in \u001b[36mconfig_doc.<locals>.config_doc_decorator.<locals>.wrap\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\USER\\Documents\\GitHub\\test-101\\.venv\\Lib\\site-packages\\xgboost\\config.py:132\u001b[39m, in \u001b[36mset_config\u001b[39m\u001b[34m(**new_config)\u001b[39m\n\u001b[32m    130\u001b[39m         not_none[k] = v\n\u001b[32m    131\u001b[39m config = json.dumps(not_none)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m _check_call(\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBSetGlobalConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern, WhiteKernel\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 1. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...\")\n",
    "df = pd.read_csv('experiment_design_27points.csv')\n",
    "\n",
    "# ‡πÅ‡∏¢‡∏Å Input ‡πÅ‡∏•‡∏∞ Output\n",
    "X = df[['Proportion1', 'Proportion2', 'Temp_C', 'Pressure_bar']]\n",
    "y = df.filter(like='Alpha_')  # Alpha_1Hz ‡∏ñ‡∏∂‡∏á Alpha_1000Hz\n",
    "\n",
    "print(f\"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Data Points: {len(df)}\")\n",
    "print(f\"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Input Features: {X.shape[1]}\")\n",
    "print(f\"‚úÖ ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Output Features (Hz): {y.shape[1]}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Standardize Input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPR (‡∏ä‡πà‡∏ß‡∏¢‡πÉ‡∏´‡πâ GPR ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô)\n",
    "# ============================================================\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ============================================================\n",
    "# 3. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤+‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥)\n",
    "# ============================================================\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏∏‡∏Å‡πÜ 10 Hz (1, 10, 20, ..., 100 Hz) ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "selected_hz = [f'Alpha_{i}Hz' for i in range(1, 101, 1)]  # 1-100 Hz\n",
    "selected_hz = [col for col in selected_hz if col in y.columns]\n",
    "y_selected = y[selected_hz]\n",
    "\n",
    "print(f\"‚úÖ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà: {len(selected_hz)} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost (‡πÉ‡∏ä‡πâ Cross-Validation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Overfitting)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ü§ñ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô XGBoost Models...\")\n",
    "\n",
    "xgb_models = {}\n",
    "xgb_scores = []\n",
    "\n",
    "for col in y_selected.columns:\n",
    "    # ‡πÉ‡∏ä‡πâ regularization parameters ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î overfitting\n",
    "    model = XGBRegressor(\n",
    "        random_state=42,\n",
    "        n_estimators=50,       # ‡∏•‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô trees ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î overfitting\n",
    "        max_depth=3,           # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å‡∏ï‡πà‡∏≥ = complexity ‡∏ï‡πà‡∏≥\n",
    "        learning_rate=0.1,\n",
    "        reg_alpha=0.1,         # L1 regularization\n",
    "        reg_lambda=1.0,        # L2 regularization\n",
    "        min_child_weight=3,    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡πÉ‡∏ô leaf\n",
    "        subsample=0.8,         # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ tree\n",
    "        colsample_bytree=0.8,\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # Leave-One-Out Cross-Validation (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢)\n",
    "    loo = LeaveOneOut()\n",
    "    cv_scores = cross_val_score(model, X, y_selected[col], cv=5, scoring='r2')\n",
    "    \n",
    "    # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢\n",
    "    model.fit(X, y_selected[col])\n",
    "    xgb_models[col] = model\n",
    "    xgb_scores.append(np.mean(cv_scores))\n",
    "\n",
    "print(f\"‚úÖ XGBoost Average R¬≤ (CV): {np.mean(xgb_scores):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• Gaussian Process Regression \n",
    "#    (‡πÉ‡∏´‡πâ Uncertainty estimate + interpolation ‡∏î‡∏µ)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô Gaussian Process Regression Models...\")\n",
    "\n",
    "gpr_models = {}\n",
    "gpr_scores = []\n",
    "\n",
    "# Kernel: RBF + White noise (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢)\n",
    "kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "\n",
    "for i, col in enumerate(y_selected.columns):\n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        n_restarts_optimizer=5,  # ‡∏´‡∏≤ hyperparameter ‡∏ó‡∏µ‡πà‡∏î‡∏µ\n",
    "        alpha=0.1,               # noise level ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏° robust\n",
    "        normalize_y=True,        # normalize output\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # ‡πÉ‡∏ä‡πâ scaled input ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GPR\n",
    "    gpr.fit(X_scaled, y_selected[col])\n",
    "    gpr_models[col] = gpr\n",
    "    \n",
    "    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì score\n",
    "    y_pred = gpr.predict(X_scaled)\n",
    "    score = r2_score(y_selected[col], y_pred)\n",
    "    gpr_scores.append(score)\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  ... ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡πâ‡∏ß {i + 1}/{len(y_selected.columns)} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\")\n",
    "\n",
    "print(f\"‚úÖ GPR Average R¬≤ (Training): {np.mean(gpr_scores):.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Ensemble Prediction (‡∏£‡∏ß‡∏° XGBoost + GPR)\n",
    "# ============================================================\n",
    "def ensemble_predict(x_input, return_std=False):\n",
    "    \"\"\"\n",
    "    ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° XGBoost ‡πÅ‡∏•‡∏∞ GPR\n",
    "    - XGBoost: ‡∏î‡∏µ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö non-linear relationships\n",
    "    - GPR: ‡πÉ‡∏´‡πâ uncertainty estimate + smooth interpolation\n",
    "    \"\"\"\n",
    "    x_array = np.array(x_input).reshape(1, -1)\n",
    "    x_scaled = scaler.transform(x_array)\n",
    "    \n",
    "    predictions = []\n",
    "    uncertainties = []\n",
    "    \n",
    "    for col in y_selected.columns:\n",
    "        # XGBoost prediction\n",
    "        xgb_pred = xgb_models[col].predict(x_array)[0]\n",
    "        \n",
    "        # GPR prediction with uncertainty\n",
    "        gpr_pred, gpr_std = gpr_models[col].predict(x_scaled, return_std=True)\n",
    "        gpr_pred = gpr_pred[0]\n",
    "        gpr_std = gpr_std[0]\n",
    "        \n",
    "        # Weighted average: ‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å GPR ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤ uncertainty ‡∏ï‡πà‡∏≥\n",
    "        weight_gpr = 1 / (1 + gpr_std)  # uncertainty ‡∏ï‡πà‡∏≥ = weight ‡∏™‡∏π‡∏á\n",
    "        weight_xgb = 1 - weight_gpr * 0.5\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = weight_xgb + weight_gpr\n",
    "        ensemble_pred = (weight_xgb * xgb_pred + weight_gpr * gpr_pred) / total_weight\n",
    "        \n",
    "        predictions.append(ensemble_pred)\n",
    "        uncertainties.append(gpr_std)\n",
    "    \n",
    "    if return_std:\n",
    "        return np.array(predictions), np.array(uncertainties)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# ============================================================\n",
    "# 7. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Target Output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Target Output...\")\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ Alpha ‡∏™‡∏π‡∏á (0.7-0.98) ‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á 1-100 Hz\n",
    "# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£\n",
    "target_output = np.linspace(0.7, 0.98, len(selected_hz))\n",
    "\n",
    "# ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á:\n",
    "# target_output = np.array([0.8] * len(selected_hz))  # ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà 0.8\n",
    "\n",
    "print(f\"  Target range: {target_output.min():.2f} - {target_output.max():.2f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 8. Objective Function (‡∏£‡∏ß‡∏° MSE + Uncertainty penalty)\n",
    "# ============================================================\n",
    "def objective_with_uncertainty(x):\n",
    "    \"\"\"\n",
    "    Objective function ‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏ó‡∏±‡πâ‡∏á MSE ‡πÅ‡∏•‡∏∞ Uncertainty\n",
    "    - ‡∏•‡∏î MSE: ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á target\n",
    "    - ‡∏•‡∏î Uncertainty: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à\n",
    "    \"\"\"\n",
    "    predictions, uncertainties = ensemble_predict(x, return_std=True)\n",
    "    \n",
    "    # Mean Squared Error\n",
    "    mse = np.mean((predictions - target_output) ** 2)\n",
    "    \n",
    "    # Uncertainty penalty (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏Å‡∏≤‡∏£ extrapolate)\n",
    "    uncertainty_penalty = np.mean(uncertainties) * 0.1\n",
    "    \n",
    "    return mse + uncertainty_penalty\n",
    "\n",
    "def objective_mse_only(x):\n",
    "    \"\"\"Objective ‡πÅ‡∏ö‡∏ö MSE ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\"\"\"\n",
    "    predictions = ensemble_predict(x, return_std=False)\n",
    "    mse = np.mean((predictions - target_output) ** 2)\n",
    "    return mse\n",
    "\n",
    "# ============================================================\n",
    "# 9. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Bounds ‡πÅ‡∏•‡∏∞ Constraints\n",
    "# ============================================================\n",
    "bounds = [\n",
    "    (X['Proportion1'].min(), X['Proportion1'].max()),\n",
    "    (X['Proportion2'].min(), X['Proportion2'].max()),\n",
    "    (X['Temp_C'].min(), X['Temp_C'].max()),\n",
    "    (X['Pressure_bar'].min(), X['Pressure_bar'].max()),\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä ‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏Ç‡∏≠‡∏á Input:\")\n",
    "print(f\"  Proportion1:  [{bounds[0][0]:.1f}, {bounds[0][1]:.1f}]\")\n",
    "print(f\"  Proportion2:  [{bounds[1][0]:.1f}, {bounds[1][1]:.1f}]\")\n",
    "print(f\"  Temp_C:       [{bounds[2][0]:.1f}, {bounds[2][1]:.1f}]\")\n",
    "print(f\"  Pressure_bar: [{bounds[3][0]:.2f}, {bounds[3][1]:.2f}]\")\n",
    "\n",
    "# ============================================================\n",
    "# 10. Global Optimization ‡∏î‡πâ‡∏ß‡∏¢ Differential Evolution\n",
    "#     (‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á Local Minima)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Optimal ‡∏î‡πâ‡∏ß‡∏¢ Differential Evolution...\")\n",
    "\n",
    "result_de = differential_evolution(\n",
    "    objective_with_uncertainty,\n",
    "    bounds,\n",
    "    seed=42,\n",
    "    maxiter=200,\n",
    "    popsize=15,\n",
    "    mutation=(0.5, 1),\n",
    "    recombination=0.7,\n",
    "    polish=True,  # polish with L-BFGS-B\n",
    "    disp=False\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ DE Optimization ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!\")\n",
    "\n",
    "# ============================================================\n",
    "# 11. Local Refinement ‡∏î‡πâ‡∏ß‡∏¢ L-BFGS-B\n",
    "# ============================================================\n",
    "print(\"\\nüîß ‡∏Å‡∏≥‡∏•‡∏±‡∏á Refine ‡∏î‡πâ‡∏ß‡∏¢ L-BFGS-B...\")\n",
    "\n",
    "result_final = minimize(\n",
    "    objective_mse_only,\n",
    "    result_de.x,\n",
    "    method='L-BFGS-B',\n",
    "    bounds=bounds,\n",
    "    options={'maxiter': 500}\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 12. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üèÜ ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Proportion1:   {result_final.x[0]:.4f}\")\n",
    "print(f\"  Proportion2:   {result_final.x[1]:.4f}\")\n",
    "print(f\"  Temp_C:        {result_final.x[2]:.4f}\")\n",
    "print(f\"  Pressure_bar:  {result_final.x[3]:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á Predicted Output\n",
    "final_pred, final_std = ensemble_predict(result_final.x, return_std=True)\n",
    "final_mse = np.mean((final_pred - target_output) ** 2)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "\n",
    "print(f\"\\nüìà ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:\")\n",
    "print(f\"  MSE:  {final_mse:.6f}\")\n",
    "print(f\"  RMSE: {final_rmse:.6f}\")\n",
    "print(f\"  Mean Uncertainty: {np.mean(final_std):.4f}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "print(f\"\\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (‡∏ó‡∏∏‡∏Å‡πÜ 10 Hz):\")\n",
    "print(f\"{'Hz':>6} | {'Target':>8} | {'Predicted':>10} | {'Error':>8} | {'Uncertainty':>12}\")\n",
    "print(\"-\" * 55)\n",
    "for i in range(0, len(selected_hz), 10):\n",
    "    hz_label = selected_hz[i].replace('Alpha_', '').replace('Hz', '')\n",
    "    print(f\"{hz_label:>6} | {target_output[i]:>8.4f} | {final_pred[i]:>10.4f} | {abs(final_pred[i]-target_output[i]):>8.4f} | {final_std[i]:>12.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 13. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á Interpolation ‡∏´‡∏£‡∏∑‡∏≠ Extrapolation\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚ö†Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡πà‡∏ß‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Interpolation Check):\")\n",
    "\n",
    "optimal_x = result_final.x\n",
    "in_range = True\n",
    "for i, col in enumerate(['Proportion1', 'Proportion2', 'Temp_C', 'Pressure_bar']):\n",
    "    min_val = X[col].min()\n",
    "    max_val = X[col].max()\n",
    "    val = optimal_x[i]\n",
    "    \n",
    "    if val < min_val or val > max_val:\n",
    "        print(f\"  ‚ö†Ô∏è {col}: {val:.4f} ‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á [{min_val:.2f}, {max_val:.2f}]\")\n",
    "        in_range = False\n",
    "    else:\n",
    "        percent = (val - min_val) / (max_val - min_val) * 100\n",
    "        print(f\"  ‚úÖ {col}: {val:.4f} (‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà {percent:.1f}% ‡∏Ç‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á)\")\n",
    "\n",
    "if in_range:\n",
    "    print(\"\\n‚úÖ ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á Interpolation - ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ô‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏ñ‡∏∑‡∏≠!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è ‡∏ö‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á - ‡∏Ñ‡∏ß‡∏£‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô\")\n",
    "\n",
    "# ============================================================\n",
    "# 14. ‡∏´‡∏≤ Top 5 Candidates (‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß (Multi-start Optimization)...\")\n",
    "\n",
    "candidates = []\n",
    "for i in range(10):\n",
    "    # Random starting point\n",
    "    x0_random = [\n",
    "        np.random.uniform(bounds[0][0], bounds[0][1]),\n",
    "        np.random.uniform(bounds[1][0], bounds[1][1]),\n",
    "        np.random.uniform(bounds[2][0], bounds[2][1]),\n",
    "        np.random.uniform(bounds[3][0], bounds[3][1]),\n",
    "    ]\n",
    "    \n",
    "    result_temp = minimize(\n",
    "        objective_mse_only,\n",
    "        x0_random,\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'maxiter': 200}\n",
    "    )\n",
    "    \n",
    "    candidates.append({\n",
    "        'x': result_temp.x,\n",
    "        'mse': result_temp.fun\n",
    "    })\n",
    "\n",
    "# Sort by MSE\n",
    "candidates = sorted(candidates, key=lambda c: c['mse'])\n",
    "\n",
    "print(\"\\nüèÖ Top 5 ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ:\")\n",
    "print(f\"{'Rank':>4} | {'Proportion1':>11} | {'Proportion2':>11} | {'Temp_C':>8} | {'Pressure':>10} | {'MSE':>10}\")\n",
    "print(\"-\" * 75)\n",
    "for i, c in enumerate(candidates[:5]):\n",
    "    print(f\"{i+1:>4} | {c['x'][0]:>11.4f} | {c['x'][1]:>11.4f} | {c['x'][2]:>8.4f} | {c['x'][3]:>10.4f} | {c['mse']:>10.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0fe40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ============================================================\n",
    "print(\"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...\")\n",
    "df = pd.read_csv('experiment_design_27points.csv')\n",
    "\n",
    "X = df[['Proportion1', 'Proportion2', 'Temp_C', 'Pressure_bar']]\n",
    "y = df.filter(like='Alpha_')\n",
    "\n",
    "# ‚ö° ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ñ‡πà 1-100 Hz (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 1000)\n",
    "selected_hz = [f'Alpha_{i}Hz' for i in range(1, 101)]\n",
    "y_selected = y[selected_hz]\n",
    "\n",
    "print(f\"‚úÖ Data: {len(df)} rows, {len(selected_hz)} outputs\")\n",
    "\n",
    "# Scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ============================================================\n",
    "# 2. ‡πÄ‡∏ó‡∏£‡∏ô XGBoost (‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å)\n",
    "# ============================================================\n",
    "print(\"\\nü§ñ ‡πÄ‡∏ó‡∏£‡∏ô XGBoost...\")\n",
    "xgb_models = {}\n",
    "for col in y_selected.columns:\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=30, max_depth=3, learning_rate=0.1,\n",
    "        reg_alpha=0.1, reg_lambda=1.0, verbosity=0, random_state=42\n",
    "    )\n",
    "    model.fit(X, y_selected[col])\n",
    "    xgb_models[col] = model\n",
    "print(\"‚úÖ XGBoost ‡πÄ‡∏™‡∏£‡πá‡∏à!\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ‡πÄ‡∏ó‡∏£‡∏ô GPR ‡πÅ‡∏Ñ‡πà 10 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (‡∏™‡∏∏‡πà‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)\n",
    "# ============================================================\n",
    "print(\"\\nüß† ‡πÄ‡∏ó‡∏£‡∏ô GPR (10 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á)...\")\n",
    "\n",
    "# ‚ö° ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏Ñ‡πà 10 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (‡∏ó‡∏∏‡∏Å‡πÜ 10 Hz)\n",
    "sample_hz = [f'Alpha_{i}Hz' for i in [1, 10, 20, 30, 40, 50, 60, 70, 80, 100]]\n",
    "\n",
    "gpr_models = {}\n",
    "kernel = Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=0.1)\n",
    "\n",
    "for col in sample_hz:\n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel, n_restarts_optimizer=2, alpha=0.1,\n",
    "        normalize_y=True, random_state=42\n",
    "    )\n",
    "    gpr.fit(X_scaled, y_selected[col])\n",
    "    gpr_models[col] = gpr\n",
    "print(\"‚úÖ GPR ‡πÄ‡∏™‡∏£‡πá‡∏à!\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Prediction Function (‡πÉ‡∏ä‡πâ XGBoost ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å)\n",
    "# ============================================================\n",
    "def predict_all(x):\n",
    "    \"\"\"‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ XGBoost (‡πÄ‡∏£‡πá‡∏ß)\"\"\"\n",
    "    x_arr = np.array(x).reshape(1, -1)\n",
    "    preds = [xgb_models[col].predict(x_arr)[0] for col in y_selected.columns]\n",
    "    return np.array(preds)\n",
    "\n",
    "def get_uncertainty(x):\n",
    "    \"\"\"‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô uncertainty ‡∏à‡∏≤‡∏Å GPR (10 ‡∏à‡∏∏‡∏î)\"\"\"\n",
    "    x_scaled = scaler.transform(np.array(x).reshape(1, -1))\n",
    "    stds = [gpr_models[col].predict(x_scaled, return_std=True)[1][0] for col in sample_hz]\n",
    "    return np.mean(stds)\n",
    "\n",
    "# ============================================================\n",
    "# 5. Target Output\n",
    "# ============================================================\n",
    "target_output = np.linspace(0.7, 0.98, len(selected_hz))\n",
    "print(f\"\\nüéØ Target: {target_output[0]:.2f} - {target_output[-1]:.2f}\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. Objective Function\n",
    "# ============================================================\n",
    "def objective(x):\n",
    "    preds = predict_all(x)\n",
    "    mse = np.mean((preds - target_output) ** 2)\n",
    "    return mse\n",
    "\n",
    "# ============================================================\n",
    "# 7. Bounds\n",
    "# ============================================================\n",
    "bounds = [\n",
    "    (X['Proportion1'].min(), X['Proportion1'].max()),\n",
    "    (X['Proportion2'].min(), X['Proportion2'].max()),\n",
    "    (X['Temp_C'].min(), X['Temp_C'].max()),\n",
    "    (X['Pressure_bar'].min(), X['Pressure_bar'].max()),\n",
    "]\n",
    "\n",
    "# ============================================================\n",
    "# 8. Optimization (‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô)\n",
    "# ============================================================\n",
    "print(\"\\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á Optimize (Differential Evolution)...\")\n",
    "\n",
    "result = differential_evolution(\n",
    "    objective, bounds,\n",
    "    seed=42, maxiter=50,  # ‚ö° ‡∏•‡∏î‡∏à‡∏≤‡∏Å 200 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 50\n",
    "    popsize=10,           # ‚ö° ‡∏•‡∏î‡∏à‡∏≤‡∏Å 15 ‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 10\n",
    "    polish=True,\n",
    "    workers=1,\n",
    "    disp=True\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 9. ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üèÜ ‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Proportion1:   {result.x[0]:.4f}\")\n",
    "print(f\"  Proportion2:   {result.x[1]:.4f}\")\n",
    "print(f\"  Temp_C:        {result.x[2]:.4f}\")\n",
    "print(f\"  Pressure_bar:  {result.x[3]:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_pred = predict_all(result.x)\n",
    "mse = np.mean((final_pred - target_output) ** 2)\n",
    "uncertainty = get_uncertainty(result.x)\n",
    "\n",
    "print(f\"\\nüìà MSE: {mse:.6f}\")\n",
    "print(f\"üìà RMSE: {np.sqrt(mse):.6f}\")\n",
    "print(f\"üìà Uncertainty (GPR): {uncertainty:.4f}\")\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•\n",
    "print(f\"\\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:\")\n",
    "print(f\"{'Hz':>6} | {'Target':>8} | {'Predicted':>10}\")\n",
    "print(\"-\" * 35)\n",
    "for i in [0, 24, 49, 74, 99]:\n",
    "    hz = selected_hz[i].replace('Alpha_', '').replace('Hz', '')\n",
    "    print(f\"{hz:>6} | {target_output[i]:>8.4f} | {final_pred[i]:>10.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d625ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.optimize import differential_evolution\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 1. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "# ============================================================\n",
    "df = pd.read_csv('experiment_design_27points.csv')\n",
    "X = df[['Proportion1', 'Proportion2', 'Temp_C', 'Pressure_bar']]\n",
    "y = df.filter(like='Alpha_')\n",
    "\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1-100 Hz\n",
    "selected_hz = [f'Alpha_{i}Hz' for i in range(1, 101)]\n",
    "y_selected = y[selected_hz]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# ============================================================\n",
    "# 2. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ Cross-Validation\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ Leave-One-Out Cross-Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 5 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ó‡∏î‡∏™‡∏≠‡∏ö\n",
    "test_cols = ['Alpha_1Hz', 'Alpha_25Hz', 'Alpha_50Hz', 'Alpha_75Hz', 'Alpha_100Hz']\n",
    "\n",
    "models = {\n",
    "    'Polynomial (deg=2)': Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=2)),\n",
    "        ('ridge', Ridge(alpha=1.0))\n",
    "    ]),\n",
    "    'SVR (RBF)': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svr', SVR(kernel='rbf', C=10, gamma='scale'))\n",
    "    ]),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=50, max_depth=5, random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=30, max_depth=3, reg_lambda=1, verbosity=0, random_state=42\n",
    "    ),\n",
    "}\n",
    "\n",
    "# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    scores = []\n",
    "    for col in test_cols:\n",
    "        cv_score = cross_val_score(model, X, y_selected[col], cv=5, scoring='r2')\n",
    "        scores.append(np.mean(cv_score))\n",
    "    results[name] = np.mean(scores)\n",
    "    print(f\"  {name:25s}: R¬≤ = {results[name]:.4f}\")\n",
    "\n",
    "# ‡∏´‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\nüèÜ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î: {best_model_name} (R¬≤ = {results[best_model_name]:.4f})\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
    "# ============================================================\n",
    "print(f\"\\nüîÑ ‡πÄ‡∏ó‡∏£‡∏ô {best_model_name} ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà...\")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "def create_model(name):\n",
    "    if name == 'Polynomial (deg=2)':\n",
    "        return Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2)),\n",
    "            ('ridge', Ridge(alpha=1.0))\n",
    "        ])\n",
    "    elif name == 'SVR (RBF)':\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('svr', SVR(kernel='rbf', C=10, gamma='scale'))\n",
    "        ])\n",
    "    elif name == 'Random Forest':\n",
    "        return RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)\n",
    "    else:  # XGBoost\n",
    "        return XGBRegressor(n_estimators=30, max_depth=3, reg_lambda=1, verbosity=0, random_state=42)\n",
    "\n",
    "# ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà\n",
    "trained_models = {}\n",
    "for col in y_selected.columns:\n",
    "    model = create_model(best_model_name)\n",
    "    model.fit(X, y_selected[col])\n",
    "    trained_models[col] = model\n",
    "\n",
    "print(f\"‚úÖ ‡πÄ‡∏ó‡∏£‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à {len(trained_models)} ‡πÇ‡∏°‡πÄ‡∏î‡∏•\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. Inverse Optimization\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Target output\n",
    "target_output = np.linspace(0.7, 0.98, len(selected_hz))\n",
    "\n",
    "def predict_all(x):\n",
    "    x_arr = np.array(x).reshape(1, -1)\n",
    "    preds = [trained_models[col].predict(x_arr)[0] for col in y_selected.columns]\n",
    "    return np.array(preds)\n",
    "\n",
    "def objective(x):\n",
    "    preds = predict_all(x)\n",
    "    mse = np.mean((preds - target_output) ** 2)\n",
    "    return mse\n",
    "\n",
    "bounds = [\n",
    "    (X['Proportion1'].min(), X['Proportion1'].max()),\n",
    "    (X['Proportion2'].min(), X['Proportion2'].max()),\n",
    "    (X['Temp_C'].min(), X['Temp_C'].max()),\n",
    "    (X['Pressure_bar'].min(), X['Pressure_bar'].max()),\n",
    "]\n",
    "\n",
    "# Optimize\n",
    "result = differential_evolution(\n",
    "    objective, bounds,\n",
    "    seed=42, maxiter=50, popsize=10,\n",
    "    polish=True, disp=True\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üèÜ ‡∏Ñ‡πà‡∏≤ Input ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Proportion1:   {result.x[0]:.4f}\")\n",
    "print(f\"  Proportion2:   {result.x[1]:.4f}\")\n",
    "print(f\"  Temp_C:        {result.x[2]:.4f}\")\n",
    "print(f\"  Pressure_bar:  {result.x[3]:.4f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_pred = predict_all(result.x)\n",
    "mse = np.mean((final_pred - target_output) ** 2)\n",
    "\n",
    "print(f\"\\nüìà MSE: {mse:.6f}\")\n",
    "print(f\"üìà RMSE: {np.sqrt(mse):.6f}\")\n",
    "\n",
    "# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•\n",
    "print(f\"\\nüìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢:\")\n",
    "print(f\"{'Hz':>6} | {'Target':>8} | {'Predicted':>10} | {'Error':>8}\")\n",
    "print(\"-\" * 45)\n",
    "for i in [0, 24, 49, 74, 99]:\n",
    "    hz = i + 1\n",
    "    err = abs(final_pred[i] - target_output[i])\n",
    "    print(f\"{hz:>6} | {target_output[i]:>8.4f} | {final_pred[i]:>10.4f} | {err:>8.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!\")\n",
    "# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 27 ‡∏à‡∏∏‡∏î ‚Üí ‡πÉ‡∏ä‡πâ SVR ‡∏´‡∏£‡∏∑‡∏≠ Polynomial Regression\n",
    "# ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ Uncertainty ‚Üí ‡πÉ‡∏ä‡πâ GPR (‡πÅ‡∏Ñ‡πà‡∏ö‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà)\n",
    "# ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß ‚Üí ‡πÉ‡∏ä‡πâ XGBoost ‡∏´‡∏£‡∏∑‡∏≠ Polynomial\n",
    "# ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î ‚Üí ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
